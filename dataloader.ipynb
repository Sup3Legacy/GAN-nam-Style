{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee17637-57e5-40ff-ade0-ffde62afa63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install librosa python-dotenv pydot\n",
    "%pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio==0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da3a9b-aaae-417d-b2e6-734419961eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_packed_sequence\n",
    "import librosa\n",
    "import utils\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52418411-1815-479e-9a0f-f2309fd7a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tracks = utils.load('../fma_metadata/tracks.csv')\n",
    "TRACKS = full_tracks[full_tracks['set', 'subset'] <= 'small']\n",
    "GENRES = utils.load('../fma_metadata/genres.csv')\n",
    "FEATURES = utils.load('../fma_metadata/features.csv')\n",
    "ECHONEST = utils.load('../fma_metadata/echonest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6252a7ce-7e01-4ba6-bd5d-9229ba09b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some files are misclipped, see issue #41 and #8\n",
    "SHORTER_IDS = [99134, 108925, 133297,  # empty\n",
    "               98565, 98567, 98569]  # < 2sec\n",
    "\n",
    "\n",
    "def prepare_fullset(musicSet, is_logmel=True, verbose=True):\n",
    "    i = 0\n",
    "    for _id, _ in musicSet.iterrows():\n",
    "        if _id in SHORTER_IDS:\n",
    "            continue\n",
    "        filename = utils.get_audio_path('../fma_small/', _id)\n",
    "        filename_root = os.path.splitext(filename)[0]\n",
    "        file_stft = filename_root + \"_stft.npy\"\n",
    "        file_logmel = filename_root + \"_log_mel.npy\"\n",
    "        log_mel_exists = os.path.isfile(file_logmel)\n",
    "        stft_exists = os.path.isfile(file_stft)\n",
    "        if not(stft_exists and is_logmel and log_mel_exists):\n",
    "            print(f\"Music {_id} does not have precomputed features... Computing them now\")\n",
    "            x, sr = librosa.load(filename, sr=None, mono=True)\n",
    "            if not stft_exists:\n",
    "                stft = np.abs(librosa.stft(x, n_fft=2048, hop_length=512))\n",
    "                np.save(file_stft, (stft, sr))\n",
    "            if is_logmel and not log_mel_exists:\n",
    "                mel = librosa.feature.melspectrogram(sr=sr, S=stft**2)\n",
    "                log_mel = librosa.amplitude_to_db(mel)\n",
    "                np.save(file_logmel, (log_mel, sr))\n",
    "        i += 1\n",
    "        if verbose and i % 100 == 0:\n",
    "            print(f\"Loaded {i} samples\")\n",
    "\n",
    "\n",
    "class MusicSetv1(Dataset):\n",
    "    def __init__(self,\n",
    "                 musicSet,\n",
    "                 is_logmel=True,\n",
    "                 device=torch.device(\"cpu\"),\n",
    "                 verbose=True):\n",
    "        prepare_fullset(musicSet, is_logmel=True, verbose=False)\n",
    "        self.songs = []\n",
    "        self.features = []\n",
    "        self.srs = []\n",
    "        i = 0\n",
    "        for _id, _ in musicSet.iterrows():\n",
    "            if _id in SHORTER_IDS:\n",
    "                continue\n",
    "            filename = utils.get_audio_path('../fma_small/', _id)\n",
    "            data_path = (os.path.splitext(filename)[0]\n",
    "                         + (\"_log_mel\" if is_logmel else \"_stft\")\n",
    "                         + \".npy\")\n",
    "            data = np.load(data_path, allow_pickle=True)\n",
    "            precomputed, sr = data\n",
    "            self.songs.append(torch.from_numpy(precomputed.T))\n",
    "            self.srs.append(sr)\n",
    "            feat = features.loc[_id]\n",
    "            self.features.append(feat)\n",
    "            i += 1\n",
    "            if verbose and i % 100 == 0:\n",
    "                print(f\"Loaded {i} samples\")\n",
    "        self.songs = sorted(self.songs, key=lambda t:t.shape[0], reverse=True)\n",
    "        self.songs = pack_sequence(self.songs, enforce_sorted=True).to(device)\n",
    "        self.songs, self.lengths = pad_packed_sequence(self.songs)\n",
    "        \"\"\"\n",
    "        max_length = sorted(map(lambda a: a.shape[1], self.songs))[-1]\n",
    "        self.songs = list(map(lambda a: np.pad(a, [(0, 0), (0, 1)],\n",
    "                                               constant_values=float(\"inf\")),\n",
    "                              self.songs))\n",
    "        self.songs = list(map(lambda a: padding(a, max_length+1, axis=1),\n",
    "                                  self.songs))\n",
    "        self.songs = torch.from_numpy(np.array(self.songs)).to(device)\n",
    "        \"\"\"\n",
    "        self.features = torch.from_numpy(np.array(self.features)).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.songs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"song\": self.songs[idx],\n",
    "                \"length\": self.lengths[idx],\n",
    "                \"sr\": self.srs[idx],\n",
    "                \"feature\": self.features[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a996695-06d9-4c30-bd37-29945d248765",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicSet(Dataset):\n",
    "    def __init__(self,\n",
    "                 musicSet,\n",
    "                 is_logmel=True,\n",
    "                 device=torch.device(\"cpu\"),\n",
    "                 verbose=True):\n",
    "        # prepare_fullset(musicSet, is_logmel=True, verbose=False)\n",
    "        self.is_logmel = True\n",
    "        self.device = device\n",
    "        self.ids = [_id for _id, _ in TRACKS.iterrows()]\n",
    "        for i in SHORTER_IDS:\n",
    "            self.ids.remove(i)\n",
    "        self.path_extension = (\"_log_mel\" if self.is_logmel else \"_stft\")\n",
    "        self.path_extension += \".npy\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _id = self.ids[idx]\n",
    "        file_audio = utils.get_audio_path('../fma_small/', _id)\n",
    "        data_path = os.path.splitext(file_audio)[0] + self.path_extension\n",
    "        data = np.load(data_path, allow_pickle=True)\n",
    "        precomputed, sr = data\n",
    "        precomputed = torch.from_numpy(precomputed).to(self.device)\n",
    "        features = FEATURES.loc[_id]\n",
    "        return (precomputed, sr, features, _id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbacbfa6-2416-4678-b30d-7ceee19d1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MusicSet(tracks, is_logmel=False, verbose=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2e233-ed50-44c2-b758-70a475321c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63cc416-c4d8-4927-80a6-58d0b9bf3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ms)\n",
    "dl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
